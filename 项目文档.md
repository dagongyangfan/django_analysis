# 主题（待定）
任务包含：对django开源项目的（待定具体）数据爬取、分析可视化、显著性检验

项目主题：开源社区核心成员流失对代码质量的影响研究
研究对象：以 django/django 为例（或其它大型活跃 Python 项目）。

一、 任务执行路线图 (Roadmap)
项目分为四个阶段，预计周期为 1-2 周。

阶段 1：数据基建 (Data Engineering)
目标：构建“开发者-Bug-代码”关联数据库。

核心动作：通过 GitHub API 抓取 Issue（Bug 类）、Commit 记录以及贡献者活跃度统计。

2. 阶段 2：特征定义与打标 (Labeling)
目标：量化“核心成员”与“修复难度”。

核心动作：

核心成员定义：累计 Commit 数前 5% 或在过去一年内贡献排名前 10 的开发者。

流失定义：在特定观察期（如 2024 年下半年）无任何活跃记录的前核心成员。

Bug 质量量化：修复耗时（Duration）、讨论热度（Comments Count）。

阶段 3：多维关联分析 (Analysis)
目标：验证假设。

核心动作：

对比分析：核心成员流失前后，Bug 修复平均时长的变化。

时间分析：周末提交 vs 工作日提交的代码，其后续产生 Bug 的概率。

复杂度分析：流失严重的模块，其代码圈复杂度（Cyclomatic Complexity）是否失控。

阶段 4：静态证据与总结 (Final Report)
目标：从代码底层提供支撑证据。

核心动作：使用 LibCST 分析典型 Bug 修复前后的代码结构变化。


# 小组成员

## 杨帆

## 陈羽飞

## 魏汉启

## 康维哲


# 使用python版本为3.12

## 1. 为什么选择这个版本？

* **稳定性与兼容性**：虽然目前（2026年）Python 3.14 和 3.26（CalVer新命名）已经发布，但 **Python 3.12/3.13** 是目前数据科学和开源分析工具链（如 `pandas`, `seaborn`, `PyGithub`）支持最完美的稳定版本。
* **性能提升**：Python 3.12 引入了更高效的垃圾回收和解释器优化，处理大型开源项目（如 Django 数万条 Issue）的爬取和数据清洗时速度更快。
* **课程工具适配**：你提到的 `libcst` 和 `z3-solver` 对 3.12+ 提供了很好的类型注解支持，这能让你在编写静态分析辅助逻辑时，利用现代 Python 的类型检查减少 Bug。

---

## 2. 环境搭建

```bash
# 创建虚拟环境
conda create -n 新环境名 python=3.12

# 安装核心依赖
pip install PyGithub pandas matplotlib seaborn

```

---


# Token

简单来说，**Token**（全称 Personal Access Token，简称 **PAT**）就是 **“数字通行证”** 或 **“专门给程序用的密码”**。

在普通的网页端，我们通过“用户名+密码”登录 GitHub；但在编写 Python 脚本调用 GitHub API 时，为了安全和功能权限的精细控制，GitHub 要求我们使用 Token。

---

## 1. 为什么不能直接用账号密码？

* **安全性**：如果脚本不小心上传到公网，泄露 Token 只需撤销该 Token 即可，而泄露密码会导致整个账号丢失。
* **权限控制**：我们可以设置一个“只读”权限的 Token，它只能抓取 Issue 数据，不能删除仓库。
* **频率限制（关键）**：
  * **匿名请求**：每小时只能发 60 次请求（抓几十个 Issue 就没了）。
  * **使用 Token**：每小时可以发 **5,000 次**请求，足以支撑你的数据分析任务。

---

## 2. 如何申请一个 Token

1. 进入申请页面  
    登录 GitHub，点击右上角个人头像，选择 Settings（设置）。  
    在左侧侧边栏拉到最底部，点击 Developer settings。  
    点击 Personal access tokens 展开菜单，选择 Tokens (classic)。  
    点击右侧的 Generate new token 按钮，选择 Generate new token (classic)。

2. 配置权限    
    Expiration (有效期)：建议选 90 days。  
    Select scopes (勾选范围)：只需要勾选 public_repo。  
    这个权限包含了读取公共仓库的 Issue、Commit、Labels 和 Star 等所有你分析所需的数据。

3. 保存并使用  
    点击页面最下方的绿色按钮 Generate token。  
    <font color = "red">看到一串以 ghp_ 开头的长字符,复制到记事本中</font>。

---

# 爬虫部分
1. 环境准备：安装 PyGithub 来调用 API，以及 pandas 处理数据。
2. 核心数据获取脚本：获取 Bug 的创建时间、修复时间以及修复者。

---

# 深入分析维度实现
1. 核心维护者变动分析（维度一）  
实现逻辑：  
统计所有修复者（fixer）的贡献排名，定义前 5% 为“核心维护者”。  
计算每个月“核心维护者”的活跃人数。  
关联分析：对比核心维护者人数减少的月份，其 Bug 的平均 duration（修复耗时）是否上升。  
可视化建议：使用双轴图。左轴为核心成员数，右轴为平均修复天数，看两者是否存在负相关。

2. 周末 vs 工作日 Bug 质量分析（维度二）  
实现逻辑：  
基于 weekday 字段，将数据分为 Workday (0-4) 和 Weekend (5-6)。  
计算指标：对比两组的 Bug 修复难度（通常修复周期越长，Bug 越复杂/隐蔽）。